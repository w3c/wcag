<!DOCTYPE html><html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><head><title>Providing audio descriptions by incorporating narration in the soundtrack</title><link rel="stylesheet" type="text/css" href="../../css/sources.css" class="remove"/></head><body><h1>Providing audio descriptions by incorporating narration in the soundtrack</h1><section class="meta"><p class="id">ID: G226</p><p class="technology">Technology: general</p><p class="type">Type: Technique</p></section><section id="applicability"><h2>When to Use</h2>
      <p>Any technology that supports audio and video.</p>
   </section><section id="description"><h2>Description</h2>
      <p>The objective of this technique is to provide audio descriptions through narration incorporated into the soundtrack of the synchronized video, so that people who cannot see are able to understand important visual material.</p>
      <p>Since most user agents today cannot merge multiple sound tracks, this technique adds additional context by revising the soundtrack so that the narration includes audio description via a single audio track. This additional information may address actions, characters, scene changes, and on-screen text (not captions) that are important to understanding the content.</p>
      <p>The narration is either revised or new narration is added during pauses in dialogue (which potentially limits the amount of supplementary narration that can be added).</p>
      <p>This technique is most appropriate in instructional, marketing, and other videos where the narration is intended to be informational. In such cases, a soundtrack which reinforces the visual "takeaways" in the video will be vital to blind people and people with low vision, and may be of use to many users, including some users with cognitive disabilities.</p>
   </section><section id="examples"><h2>Examples</h2>
      <h3>An instructional video is scripted with narration that describes important visual content</h3>
   <p>Someone creating an instructional video demonstrating the features of an application prepares a script where what is being shown visually is reinforced through the narration, to arrive at an efficient and cost-effective means of making a more accessible video.</p>
   <p>Several key strategies are followed to improve the video's narration. Each is described more fully in the following subsections:</p>
   <ol>
      <li>Describe any pertinent and meaningful text on the screen</li>
      <li>Avoid saying only “this” or “here” to describe UI components</li>
      <li>For better context, describe elements by sensory perceptions as well as by label</li>
      <li>Fully describe sequences of action, including any dynamic content that appears</li>
      <li>When a main page or dialog appears, say its title and describe its features</li>
      <li>When using a mouse to show something (such as to hover, select, scroll, and open), say what you are doing</li>
   </ol>
   <h4>Describe any pertinent and meaningful text on the screen</h4>
   <p>When referring to URLs, dialogs, labels, and headings, read out the text. Sometimes presenters (narrators) just highlight or point to text; speaking the visible text ensures this meaningful text is made accessible to everyone including blind users or those with low vision. When describing actions a user can do, be sure to specifically state the button names to improve the context (for example, "choose the green 'Go' button").</p>
   <h4>Avoid saying only “this” or “here” to describe UI components</h4>
   <p>This goes hand in hand with the first rule to announce text on the screen. When presenters (narrators) point out “this button” or say “you'll see this”, they are typically referring to a visual cue they are providing on the screen. Someone who can't see the screen lacks the context to understand what is being referenced. Replace or augment “this” and “here” with the labels/titles to provide context: “Choose the blue Save button”, “The Profile Settings dialog appears, with several options.”</p>
   <h4>For better context, describe elements by sensory perceptions as well as by label</h4>
   <p>Including position and other sensory qualities like color can really help some low vision users and users with cognitive disabilities. However, you will want to include other context, such as structural headings, in addition to position (which is usually not very helpful to blind user). For components with visible labels, always read out the label when referring to the component. Where a visible label is absent, but you are aware of other programmatic labeling that will be read by the screen reader (for example, the <code>aria-label</code> property or page regions), use that text. Also include placement and structure (headings) on the page (for example, “the red “Cancel” button at the bottom right of the dialog”, “Select the “online only” radio button in the Settings options”).</p>
   <h4>Fully describe sequences of action, including any dynamic content that appears</h4>
   <p>When you are demonstrating a process, be sure to describe all steps you are carrying out. As well, announce when status messages appear, such as “loading”, and when other content appears or disappears on the screen.</p>
   <h4>When a main page or dialog appears, say its title and describe its features</h4>
   <p>When a dialog or page appears, read out its title. For a new page, also describe its purpose or any distinguishing characteristics. Practice a natural storytelling style that does not simply read the text on the screen.</p>
   <h4>When using a mouse to show something (such as to hover, select, scroll, or open), say what you are doing</h4>
   <p>When performing complex interactions, especially by mouse, it is sometimes helpful to announce what you plan to do before doing it, then narrate while you are interacting with it, and finally summarize what you just did.</p>
   <h3>Additional narration is added to gaps in the soundtrack</h3>
   <p>A marketing video's important visuals can be mainly inferred from the audio soundtrack. However, it only uses on-screen text to identify new speakers, as well as to provide a url at the end of the video where people can go for more information. In post-production a new narrator announces the onscreen text in gaps in the dialog.</p>
   </section><section id="tests"><h2>Tests</h2>
      <section class="procedure"><h3>Procedure</h3>
         <ol>
            <li>Open the synchronized media that includes audio description.</li>
            <li>Review the video.</li>
            <li>Check to see if the main narration is used to convey important information in the visual content, such as new speakers and on-screen text.</li>
            <li>Where important visual information is not conveyed through the soundtrack or addressed in the original narration, check to see if additional narration has been added in available gaps in the dialog.</li>
         </ol>
      </section>
      <section class="results"><h3>Expected Results</h3>
         <ul>
            <li>#3 and #4 are true.</li>
         </ul>
      </section>
   </section><section id="related"><h2>Related Techniques</h2><ul>
      <li><a href="../general/G78">G78</a></li>
      <li><a href="../general/G69">G69</a></li>
   </ul></section></body></html>