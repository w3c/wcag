<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
   <head>
      <meta charset="UTF-8" />
      <title>FLASH26: Applying audio descriptions to Flash video</title>
      <link rel="stylesheet" type="text/css" href="https://www.w3.org/StyleSheets/TR/2016/base" />
      <link rel="stylesheet" type="text/css" href="base.css" />
      <link rel="stylesheet" type="text/css" href="../techniques.css" />
      <link rel="stylesheet" type="text/css" href="../slicenav.css" />
   </head>
   <body>
      <nav>
         <ul id="navigation">
            <li><a href="https://w3c.github.io/wcag/techniques/#techniques" title="Table of Contents">Contents</a></li>
            <li><a href="https://w3c.github.io/wcag/techniques/#introduction" title="Introduction to Techniques">Intro</a></li>
            <li><a href="FLASH25">Previous Technique: FLASH25</a></li>
            <li><a href="FLASH27">Next Technique: FLASH27</a></li>
         </ul>
      </nav>
      <nav class="navtoc">
         <p>On this page:</p>
         <ul id="navbar">
            <li><a href="#important-information">Important Information about Techniques</a></li>
            <li><a href="#applicability">Applicability</a></li>
            <li><a href="#description">Description</a></li>
            <li><a href="#examples">Examples</a></li>
            <li><a href="#related">Related Techniques</a></li>
            <li><a href="#tests">Tests</a></li>
         </ul>
      </nav>
      <h1>Applying audio descriptions to Flash video</h1>
      <section id="important-information">
         <h2>Important Information about Techniques</h2>
         <p>See <a href="https://w3c.github.io/wcag/understanding/understanding-techniques">Understanding Techniques for WCAG Success Criteria</a> for important information about the usage of these informative techniques and how
            they relate to the normative WCAG 2.1 success criteria. The Applicability section
            explains the scope of the technique, and the presence of techniques for a specific
            technology does not imply that the technology can be used in all situations to create
            content that meets WCAG 2.1.
         </p>
      </section>
      <main>
         <section id="applicability">
            <h2>Applicability</h2>
            <ul>
               
               <li> Flash CS3 and higher </li>
               
               <li> ActionScript 3.0 and higher </li>
               
            </ul>
            <div class="note">
               <div role="heading" class="note-title marker" aria-level="3">Note</div>
               <p>Adobe has plans to stop updating and distributing the Flash Player at the end of 2020,
                  and encourages authors interested in creating accessible web content to use HTML.
               </p>
            </div>
            <p>This technique relates to:</p>
            <ul>
               <li><a href="https://w3c.github.io/wcag/understanding/audio-description-or-media-alternative-prerecorded">Success Criterion 1.2.3: Audio Description or Media Alternative (Prerecorded)</a> (Sufficient as a way to meet <a href="../general/G173">G173: Providing a version of a movie with audio descriptions</a>)
               </li>
               <li><a href="https://w3c.github.io/wcag/understanding/audio-description-or-media-alternative-prerecorded">Success Criterion 1.2.3: Audio Description or Media Alternative (Prerecorded)</a> (Sufficient as a way to meet <a href="../general/G8">G8: Providing a movie with extended audio descriptions</a>)
               </li>
               <li><a href="https://w3c.github.io/wcag/understanding/audio-description-prerecorded">Success Criterion 1.2.5: Audio Description (Prerecorded)</a> (Sufficient as a way to meet <a href="../general/G173">G173: Providing a version of a movie with audio descriptions</a>)
               </li>
               <li><a href="https://w3c.github.io/wcag/understanding/audio-description-prerecorded">Success Criterion 1.2.5: Audio Description (Prerecorded)</a> (Sufficient as a way to meet <a href="../general/G8">G8: Providing a movie with extended audio descriptions</a>)
               </li>
            </ul>
         </section>
         <section id="description">
            <h2>Description</h2>
            <p>The objective of this technique is to provide a way for people
               				who are blind or otherwise have trouble seeing the video in
               				audio-visual material to be able to access the material. With
               				this technique a description of the video is provided via audio
               				description that will fit into the gaps in the dialogue in
               				the audio-visual material. 
            </p>
         </section>
         <section id="examples">
            <h2>Examples</h2>
            <section class="example" id="example-1-playing-descriptions-when-cue-points-are-reached">
               <h3>Example 1: Playing descriptions when cue points are reached</h3>
               <p>In this example, the FLVPlayback component is used to create
                  						a video player. A custom class called "AudioDescriptions" is
                  						added to manage the playback of extended audio descriptions.
                  						This class provides event listeners to listen for cue points
                  						in the media that have been identified by the audio description
                  						provider. When these cuepoints are reached, an mp3 file containing
                  						the corresponding description will start playing. The recorded
                  						descriptions have been timed to fit with in the gaps in the
                  						movie's dialog. 
               </p>
               <p>By default, audio descriptions will be enabled. A button (which
                  						must itself be accessible to meet other success criteria) is
                  						provided below the video player that allows the user to turn
                  						audio descriptions on or off. 
               </p><pre xml:space="preserve">package {
  import fl.video. *;
  import flash.events. *;
  import flash.media.Sound;
  import flash.media.SoundChannel;
  import flash.net.URLRequest;
  import flash.display.Sprite;
  
  public class AudioDescriptions extends Sprite {
    private var channel: SoundChannel = new SoundChannel;
    private var myPlayer: FLVPlayback;
    private var _enabled: Boolean = true;
    private var _toggleBtn: Button;
    private var snd: Sound = new Sound();
    public function AudioDescriptions() {
      // point myPlayer to the FLVPlayback component instance on the stage, 
      // which should be loaded with a valid video source.
      myPlayer = my_FLVPlybk;
      // add cue points. When any of these are reached, the 
      // MetadataEvent.CUE_POINT event will fire
      myPlayer.addASCuePoint(8.35, "ASpt1");
      myPlayer.addASCuePoint(23.23, "ASpt2");
      
      enable();
      
      enable_AD_btn.addEventListener(MouseEvent.CLICK, handleBtnClick);
    }
    
    private function handleBtnClick(e) {
      _enabled = ! _enabled;
      if (! _enabled) {
        disable();
        enable_AD_btn.label = "Enable Audio Descriptions";
      } else {
        enable();
        enable_AD_btn.label = "Disable Audio Descriptions";
      }
    }
    
    public function enable() {
      // set up an event handler which will be called each time a cue point is reached
      myPlayer.addEventListener(MetadataEvent.CUE_POINT, cp_listener);
    }
    
    public function disable() {
      // remove the event handler called each time a cue point is reached, so 
      // that audio description is disabled.
      myPlayer.removeEventListener(MetadataEvent.CUE_POINT, cp_listener);
    }
    
    private function cp_listener(eventObject: MetadataEvent): void {
      snd = new Sound();
      //recreate sound object as it can only load one mp3 file
      //check to see which cue point was reached
      switch (eventObject.info.name) {
        case "ASpt1":
        snd.load(new URLRequest("sphere.mp3"));
        //create a new Sound object, and load the appropriate mp3
        channel = snd.play();
        // play the audio description, and assign it to the SoundChannel object
        break;
        case "ASpt2":
        snd.load(new URLRequest("transfrm.mp3"));
        channel = snd.play();
        break;
      }
    }
  }
}</pre><p class="working-example">The result can be viewed in the <a href="../../working-examples/flash-audio-descriptions/">working version of Playing descriptions when cue points are reached</a>. The <a href="../../working-examples/flash-audio-descriptions/audio_descriptions_as3.zip">source of Playing descriptions when cue points are reached</a> is available.
               </p>
            </section>
            <section class="example" id="example-2-providing-an-additional-audio-track-for-descriptions">
               <h3>Example 2: Providing an additional audio track for descriptions</h3>
               <p>Audio description can also be provided via an additional audio
                  						track that is the same length and plays simultaneously as the
                  						primary media, but that only includes sound for the segments
                  						when audio description needs to be played and silence at other
                  						times. A Flash author can provide a toggle to turn this additional
                  						audio track on or off, based on the listener's preference.
                  						When the additional track is enabled, there are two parallel
                  						audio tracks, one being the primary audio, and the second being
                  						the one containing only audio description. It is still necessary
                  						to ensure that the audio description and primary audio do not
                  						overlap in ways that make comprehension difficult. This method
                  						will achieve the same result as the method used in Example
                  						1, but may be chosen because of the type of audio description
                  						files that are provided to the Flash author. 
               </p>
            </section>
         </section>
         <section id="related">
            <h2>Related Techniques</h2>
            <ul>
               
               <li><a href="https://w3c.github.io/wcag/techniques/general/G78">G78: Providing a second, user-selectable, audio track that includes audio descriptions</a></li>
               
               <li><a href="https://w3c.github.io/wcag/techniques/general/G69">G69: Providing an alternative for time based media</a></li>
               
               <li><a href="https://w3c.github.io/wcag/techniques/general/G173">G173: Providing a version of a movie with audio descriptions</a></li>
               
            </ul>
         </section>
         <section id="tests">
            <h2>Tests</h2>
            <section class="procedure" id="procedure">
               <h3>Procedure</h3>
               
               <p>When Flash content contains video with an audio soundtrack,
                  					confirm that: 
               </p>
               
               <ol>
                  
                  <li> Audio descriptions have been made available using separate
                     					sound files. 
                  </li>
                  
                  <li> A button is provided that allows users to enable or disable
                     					the audio descriptions 
                  </li>
                  
               </ol>
               
            </section>
            <section class="results" id="expected-results">
               <h3>Expected Results</h3>
               
               <ul>
                  
                  <li> #1 and #2 are true </li>
                  
               </ul>
               
            </section>
         </section>
      </main>
   </body>
</html>